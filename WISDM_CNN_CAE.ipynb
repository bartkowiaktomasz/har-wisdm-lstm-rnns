{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JCo9NnxgwFNH"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "from keras import optimizers, Sequential\n",
    "from tensorflow.keras.losses import binary_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.python.keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1DTranspose, Dense, LSTM, RepeatVector, TimeDistributed, Input, concatenate, Conv2D, MaxPooling3D, Activation, UpSampling2D, BatchNormalization, add, concatenate, Lambda, Flatten, Conv2DTranspose,DepthwiseConv2D,ConvLSTM2D,TimeDistributed,Dropout, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder\n",
    "from scipy import stats\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(7)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 123 #used to help randomly select the data points\n",
    "DATA_SPLIT_PCT = 0.2\n",
    "\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "LABELS = [\"Normal\",\"Break\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH8yODF6z9tD"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbr5k6oOwTRC",
    "outputId": "c2871fb7-8fbe-46c7-b70a-b6e23e7b55a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'har-wisdm-lstm-rnns' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bartkowiaktomasz/har-wisdm-lstm-rnns.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LK5W80ewfO5"
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "COLUMN_NAMES = [\n",
    "    'user',\n",
    "    'activity',\n",
    "    'timestamp',\n",
    "    'x-axis',\n",
    "    'y-axis',\n",
    "    'z-axis'\n",
    "]\n",
    "LABELS = [\n",
    "    'Downstairs',\n",
    "    'Jogging',\n",
    "    'Sitting',\n",
    "    'Standing',\n",
    "    'Upstairs',\n",
    "    'Walking'\n",
    "]\n",
    "dataset=pd.read_csv(\"/content/har-wisdm-lstm-rnns/data/WISDM_ar_v1.1_raw.txt\",header=None,names=COLUMN_NAMES )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rd_PW4TewhSk"
   },
   "outputs": [],
   "source": [
    "dataset['z-axis'].replace(to_replace=r';',value=r'',regex=True,inplace=True)\n",
    "dataset['z-axis'] = dataset['z-axis'].astype('float')\n",
    "dataset.dropna(axis=0, how='any', inplace=True)\n",
    "dataset.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JCbEvVNwi7X"
   },
   "outputs": [],
   "source": [
    "dataset[['timestamp','x-axis','y-axis','z-axis','activity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjuA9zICwmQc"
   },
   "outputs": [],
   "source": [
    "dataset[['timestamp','x-axis','y-axis','z-axis','activity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1iuAGKTxYhq"
   },
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "labeled=enc.fit_transform(dataset.loc[:,('activity')].ravel())\n",
    "dataset['labeled_activites']=labeled\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ph1-h9e-wmsq"
   },
   "outputs": [],
   "source": [
    "mag=np.sqrt(dataset['x-axis']**2+dataset['y-axis']**2+dataset['z-axis']**2)\n",
    "dataset['magnitude']=mag\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FL7bY0rwqBA"
   },
   "outputs": [],
   "source": [
    "x=dataset.iloc[:,3:6]\n",
    "#digitizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='kmeans')\n",
    "#x = digitizer.fit_transform(x)\n",
    "\n",
    "x=(x-x.mean())/x.std()\n",
    "x=pd.DataFrame(x,columns={'x-axis','y-axis','z-axis'})\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u06OX3Uawsft"
   },
   "outputs": [],
   "source": [
    "dataset['x-axis'] = x['x-axis']\n",
    "dataset['y-axis'] = x['y-axis']\n",
    "dataset['z-axis'] = x['z-axis']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saUsEQhB0OSJ"
   },
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yln_Vf1Rwz5w"
   },
   "outputs": [],
   "source": [
    "train=dataset[dataset['user']<=28]\n",
    "test=dataset[dataset['user']>28]\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B63mHCLB0VLS"
   },
   "source": [
    "# Sliding window on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgiKO_H4w1F2"
   },
   "outputs": [],
   "source": [
    "def sliding_window(dataframe,time_steps,steps):\n",
    "  xs=[]\n",
    "  ys=[]\n",
    "  for i in range(0,len(dataframe)-time_steps,steps):\n",
    "    ext_step=i+time_steps\n",
    "    if ext_step>len(dataframe)-1:\n",
    "      break\n",
    "    xi=dataframe['x-axis'].values[i:i+time_steps]\n",
    "    y1=dataframe['y-axis'].values[i:i+time_steps]\n",
    "    z1=dataframe['z-axis'].values[i:i+time_steps]\n",
    "    yi=stats.mode(dataframe['labeled_activites'][i:i+time_steps])[0][0]\n",
    "    xs.append([xi,y1,z1])\n",
    "    ys.append(yi)\n",
    "  return np.asarray(xs),np.asarray(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8Mm0trbw1ux"
   },
   "outputs": [],
   "source": [
    "x_train,y_train=sliding_window(train,90,10)\n",
    "x_test,y_test=sliding_window(test,90,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4KTuwZ8xwu9"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzfvPaBVw4J1"
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(-1,90,3).astype(np.float32)\n",
    "x_test=x_test.reshape(-1,90,3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZ1_I5QO0T_c"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGDnlQAQ0jk5"
   },
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXA60BT2i1HC"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model=keras.models.Sequential([tf.keras.layers.Input(shape=[90,3]),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(128,5,activation ='relu',padding=\"same\"),\n",
    "    #tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(128,5,activation ='relu',padding=\"same\"),\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(256,5,activation ='relu',padding=\"same\"),\n",
    "    #tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.Dropout(0.35),\n",
    "    tf.keras.layers.Conv1D(256,5,activation ='relu',padding=\"same\"),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "   tf.keras.layers.Dense(12),\n",
    "    tf.keras.layers.Dense(6,activation=\"softmax\")\n",
    "\n",
    "                               ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quxF69VA01Rb"
   },
   "source": [
    "# Convolutional Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbUsaMJVhnUW"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model=keras.models.Sequential([tf.keras.layers.Input(shape=[90,3]),\n",
    "                                 \n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=64, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6,activation=\"softmax\")\n",
    "\n",
    "                               ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxHH7a3f0wqc"
   },
   "outputs": [],
   "source": [
    "model=create_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xjsd7tXU1bNV"
   },
   "outputs": [],
   "source": [
    "Y_train=keras.utils.to_categorical(y_train,num_classes=6)\n",
    "Y_test=keras.utils.to_categorical(y_test,num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1XGS_2q1NOB"
   },
   "outputs": [],
   "source": [
    "checkpoint=keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=1, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "reduce_LOP=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=0, min_lr=0.001)\n",
    "Callbacks=[checkpoint,reduce_LOP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3vc_i_O1U58"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Il1V0c831RrJ"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "history=model.fit(x_train,Y_train,batch_size=512,epochs=100,verbose=1,validation_data=(x_test,Y_test),callbacks=Callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoXklGSr1Y90"
   },
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dMRF6X3g5-_"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='valid-accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwORnNQVg824"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['val_loss'],label='valid-loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2oLwcZZr7f5"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('best_model.93-0.36.h5')\n",
    "pred_train=model.predict(x_train)\n",
    "y_pred_train=np.argmax(pred_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBU23sbSsQs2"
   },
   "outputs": [],
   "source": [
    "    # CONFUSION MATRIX\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train,y_pred_train)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True);\n",
    "    plt.title(\"Confusion matrix on Train Data\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk7cROhVsTaJ"
   },
   "outputs": [],
   "source": [
    "    # CONFUSION MATRIX\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train,y_pred_train)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(confusion_matrix/(np.sum(confusion_matrix, axis=1, keepdims=1)), xticklabels=LABELS, yticklabels=LABELS, annot=True);\n",
    "    plt.title(\"Confusion matrix on Train Data (with normalization)\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjVpxIC1sU2C"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('best_model.93-0.36.h5')\n",
    "pred_test=model.predict(x_test)\n",
    "y_pred_test=np.argmax(pred_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDVbr59bsZAp"
   },
   "outputs": [],
   "source": [
    "    # CONFUSION MATRIX\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test,y_pred_test)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True);\n",
    "    plt.title(\"Confusion matrix on Test data\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iir_MKQSsara"
   },
   "outputs": [],
   "source": [
    "    # CONFUSION MATRIX\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test,y_pred_test)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(confusion_matrix/(np.sum(confusion_matrix, axis=1, keepdims=1)), xticklabels=LABELS, yticklabels=LABELS, annot=True);\n",
    "    plt.title(\"Confusion matrix on Test Data (with normalization)\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WISDM_CNN_CAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
